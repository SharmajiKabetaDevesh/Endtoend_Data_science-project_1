{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\mlops\\\\etoe1ds'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box({'block': 'Bward, Jail Road', 'FlatNo.': '301,C-wing', 'BuildingName': 'LullaComplex'})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from box import box\n",
    "from box import Box,ConfigBox\n",
    "data=Box({\"name\":\"Devesh\",\n",
    "      \"rno.\":\"27\",\n",
    "    \"room\":2,\n",
    "    \"address\":{\n",
    "        \"block\":\"Bward, Jail Road\",\n",
    "        \"FlatNo.\":\"301,C-wing\",\n",
    "        \"BuildingName\":\"LullaComplex\"\n",
    "    }\n",
    "    \n",
    "      })\n",
    "\n",
    "data.address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    root_dir:Path\n",
    "    source_url:str\n",
    "    local_data_file:Path\n",
    "    unzip_dir:Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datascience.constants import *\n",
    "from src.datascience.utils.common import  read_yaml ,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,config_filepath=CONFIG_FILE_PATH,\n",
    "                 params_filepath=PARAMS_FILE_PATH,\n",
    "                 schema_filepath=SCHEMA_FILE_PATH):\n",
    "        self.config=read_yaml(config_filepath)\n",
    "        self.params=read_yaml(params_filepath)\n",
    "        self.schema=read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self)-> DataIngestionConfig:\n",
    "        config=self.config.data_ingestion\n",
    "        create_directories([config.root_dir])\n",
    "        data_ingestion_config=DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_url=config.source_url,\n",
    "            local_data_file=config.local_data_file,\n",
    "            unzip_dir=config.unzip_dir\n",
    "        )\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/mlops/etoe1ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\mlops\\\\etoe1ds'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.datascience import logger\n",
    "import urllib.request as request\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#component for data ingestion\n",
    "class DataIngestion:\n",
    "    def __init__(self,config:DataIngestionConfig):\n",
    "        self.config=config\n",
    "    def download_file(self):\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            filename,headers =request.urlretrieve(\n",
    "                url = self.config.source_url,\n",
    "                filename=self.config.local_data_file\n",
    "            )\n",
    "            logger.info(f\"{filename } downloaded\")\n",
    "        else:\n",
    "            logger.info(f\"FIles is present\")\n",
    "    def extract_zip_file(self):\n",
    "        unzip_path= self.config.unzip_dir\n",
    "        os.makedirs(unzip_path,exist_ok=True)\n",
    "        with zipfile.ZipFile(self.config.local_data_file,'r')as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-29 16:03:34,999: INFO: common: yaml file: config\\config.yaml loading successfull]\n",
      "[2025-01-29 16:03:35,002: INFO: common: yaml file: params.yaml loading successfull]\n",
      "[2025-01-29 16:03:35,006: INFO: common: yaml file: schema.yaml loading successfull]\n",
      "[2025-01-29 16:03:35,008: INFO: common: Cretaed directory at:artifacts]\n",
      "[2025-01-29 16:03:35,009: INFO: common: Cretaed directory at:artifacts/data_ingestion]\n",
      "[2025-01-29 16:03:35,011: INFO: 750986838: FIles is present]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config=ConfigurationManager()\n",
    "    data_ingestion_config=config.get_data_ingestion_config()\n",
    "    data_ingestion=DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\mlops\\\\etoe1ds'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(\"artifacts/data_ingestion/winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
       "0            7.4              0.70         0.00  ...       0.56      9.4        5\n",
       "1            7.8              0.88         0.00  ...       0.68      9.8        5\n",
       "2            7.8              0.76         0.04  ...       0.65      9.8        5\n",
       "3           11.2              0.28         0.56  ...       0.58      9.8        6\n",
       "4            7.4              0.70         0.00  ...       0.56      9.4        5\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataValidationConfig:\n",
    "    root_dir:Path\n",
    "    STATUS_FILE:str\n",
    "    unzip_data_dir:Path\n",
    "    all_schema:dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datascience.utils.common import read_yaml,create_directories\n",
    "from src.datascience.constants import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationConfigurationManager:\n",
    "    def __init__(self,config_filepath=CONFIG_FILE_PATH,params_filepath=PARAMS_FILE_PATH,schema_filepath=SCHEMA_FILE_PATH):\n",
    "        self.config=read_yaml(config_filepath)\n",
    "        self.params=read_yaml(params_filepath)\n",
    "        self.schema=read_yaml(schema_filepath)\n",
    "        create_directories([self.config.artifacts_root,self.config.data_validation.root_dir])\n",
    "    \n",
    "    def get_data_validation_config(self)->DataValidationConfig:\n",
    "        config=self.config.data_validation\n",
    "        schema=self.schema.columns\n",
    "        data_validation_config= DataValidationConfig(\n",
    "               root_dir=config.root_dir,\n",
    "               STATUS_FILE=config.STATUS_FILE,\n",
    "               unzip_data_dir=config.unzip_data_dir,\n",
    "               all_schema=schema\n",
    "        )\n",
    "        return data_validation_config\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.datascience import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidator:\n",
    "    def __init__(self,config:DataValidationConfig):\n",
    "        self.config=config\n",
    "    \n",
    "    def validate_all_columns(self)-> bool:\n",
    "        try:\n",
    "            validation_status=None\n",
    "            data = pd.read_csv(self.config.unzip_data_dir)\n",
    "            all_cols= list(data.columns)\n",
    "            all_schema = self.config.all_schema.keys()\n",
    "\n",
    "            for col in all_cols:\n",
    "                if col not in all_schema:\n",
    "                    validation_status= False\n",
    "                    with open(self.config.STATUS_FILE,'w')as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "                else:\n",
    "                    validation_status= True\n",
    "                    with open(self.config.STATUS_FILE,'w') as f:\n",
    "                        f.write(f\"Validation Status:{validation_status}\")\n",
    "                   \n",
    "            \n",
    "            return validation_status\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datascience import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-29 16:03:35,315: INFO: 2505702399: Data Validation has been started]\n",
      "[2025-01-29 16:03:35,324: INFO: common: yaml file: config\\config.yaml loading successfull]\n",
      "[2025-01-29 16:03:35,327: INFO: common: yaml file: params.yaml loading successfull]\n",
      "[2025-01-29 16:03:35,331: INFO: common: yaml file: schema.yaml loading successfull]\n",
      "[2025-01-29 16:03:35,333: INFO: common: Cretaed directory at:artifacts]\n",
      "[2025-01-29 16:03:35,334: INFO: common: Cretaed directory at:artifacts/data_validation]\n",
      "[2025-01-29 16:03:35,343: INFO: 2505702399: Data Validation has ended]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logger.info(\"Data Validation has been started\")\n",
    "    obj=ValidationConfigurationManager()\n",
    "    data_validation_config=obj.get_data_validation_config()\n",
    "    data_validator=DataValidator(config=data_validation_config)\n",
    "    output=data_validator.validate_all_columns()\n",
    "    logger.info(\"Data Validation has ended\")\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Data Validation error: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datascience.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir:Path\n",
    "    data_path:Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datascience.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformationConfigurationManager:\n",
    "    def __init__(self,\n",
    "                config_path=CONFIG_FILE_PATH,\n",
    "                params_path=PARAMS_FILE_PATH,\n",
    "                schema_path=SCHEMA_FILE_PATH\n",
    "                ):\n",
    "        self.config=read_yaml(config_path)\n",
    "        self.params=read_yaml(params_path)\n",
    "        self.schema=read_yaml(schema_path)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self)->DataTransformationConfig:\n",
    "        config=self.config.data_transformation\n",
    "        create_directories([config.root_dir])\n",
    "        data_transformation_config=DataTransformationConfig(\n",
    "           root_dir=config.root_dir,\n",
    "           data_path=config.data_path\n",
    "        )\n",
    "        return data_transformation_config\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.datascience import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self,config:DataTransformationConfig):\n",
    "        self.config=config\n",
    "\n",
    "    def splitting_data(self):\n",
    "        data=pd.read_csv(config.data_path)\n",
    "        train,test=train_test_split(data)\n",
    "        train.to_csv(os.path.join(self.config.root_dir,\"train.csv\"),index=False)\n",
    "        test.to_csv(os.path.join(self.config.root_dir,\"test.csv\"),index=False)\n",
    "        logger.info(\"Splitted the data into train and test\")\n",
    "        logger.info(f\"Train Size:{train.shape}\")\n",
    "        logger.info(f\"Test Size:{test.shape}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-29 16:03:35,550: INFO: 435105784: Data Transformation has started]\n",
      "[2025-01-29 16:03:35,554: INFO: common: yaml file: config\\config.yaml loading successfull]\n",
      "[2025-01-29 16:03:35,557: INFO: common: yaml file: params.yaml loading successfull]\n",
      "[2025-01-29 16:03:35,562: INFO: common: yaml file: schema.yaml loading successfull]\n",
      "[2025-01-29 16:03:35,565: INFO: common: Cretaed directory at:artifacts]\n",
      "[2025-01-29 16:03:35,567: INFO: common: Cretaed directory at:artifacts/data_transformations]\n",
      "[2025-01-29 16:03:35,615: INFO: 1575699340: Splitted the data into train and test]\n",
      "[2025-01-29 16:03:35,616: INFO: 1575699340: Train Size:(1199, 12)]\n",
      "[2025-01-29 16:03:35,618: INFO: 1575699340: Test Size:(400, 12)]\n",
      "[2025-01-29 16:03:35,620: INFO: 435105784: Data Transformation ended ,data saved to artifacts.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logger.info(f\"Data Transformation has started\")\n",
    "    obj=TransformationConfigurationManager()\n",
    "    config=obj.get_data_transformation_config()\n",
    "    DataTransformation(config).splitting_data()\n",
    "    logger.info(f\"Data Transformation ended ,data saved to artifacts.\")\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model training\n",
    "# import os\n",
    "# os.chdir(\"mlops/etoe1ds\")\n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "#  root_dir: artifacts/model_trainer\n",
    "#   train_data_path: artifacts/data_transformation/train.csv\n",
    "#   test_data_path: artifacts/data_transformation/test.csv\n",
    "#   model_name: model.joblib\n",
    "\n",
    "@dataclass\n",
    "class DataTraningConfig:\n",
    "    root_dir:Path\n",
    "    train_data_path:Path\n",
    "    test_data_path:Path\n",
    "    model_name:Path\n",
    "    alpha:float\n",
    "    l1_ratio:float\n",
    "    target_column: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datascience.utils.common import *\n",
    "class TrainerConfigurationManager:\n",
    "    def __init__(self,\n",
    "        config_path =CONFIG_FILE_PATH,\n",
    "        params_path= PARAMS_FILE_PATH,\n",
    "        schema_path= SCHEMA_FILE_PATH    \n",
    "                 ):\n",
    "        self.config=read_yaml(config_path)\n",
    "        self.params=read_yaml(params_path)\n",
    "        self.schema=read_yaml(schema_path)\n",
    "    def get_data_training_config(self)->DataTraningConfig:\n",
    "        \n",
    "        config=self.config.model_trainer\n",
    "        create_directories([config.root_dir])\n",
    "        params=self.params.ElasticNet\n",
    "        schema =self.schema.target_value\n",
    "        output=DataTraningConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "            alpha=params.l1_ratio,\n",
    "            l1_ratio=params.l1_ratio,\n",
    "            target_column=schema.name\n",
    "        )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from src.datascience.utils.common import save_model\n",
    "from src.datascience import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "class Trainer:\n",
    "    def __init__(self,config=DataTraningConfig):\n",
    "        self.config=config\n",
    "\n",
    "    def train_model(self):\n",
    "        train_data= pd.read_csv(self.config.train_data_path)\n",
    "        test_data= pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "        train_x = train_data.drop([self.config.target_column],axis=1)\n",
    "        test_x = test_data.drop([self.config.target_column],axis=1)\n",
    "        train_y= train_data[self.config.target_column]\n",
    "        test_y= test_data[self.config.target_column]\n",
    "        lr = ElasticNet(alpha=self.config.alpha,l1_ratio=self.config.l1_ratio,random_state=42)\n",
    "        lr.fit(train_x,train_y)\n",
    "        joblib.dump(lr,os.path.join(self.config.root_dir,self.config.model_name))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-29 16:08:34,970: INFO: common: yaml file: config\\config.yaml loading successfull]\n",
      "[2025-01-29 16:08:34,973: INFO: common: yaml file: params.yaml loading successfull]\n",
      "[2025-01-29 16:08:34,976: INFO: common: yaml file: schema.yaml loading successfull]\n",
      "[2025-01-29 16:08:34,978: INFO: common: Cretaed directory at:artifacts/model_trainer]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    obj= TrainerConfigurationManager()\n",
    "    config=obj.get_data_training_config()\n",
    "    Trainer(config).train_model()\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as SharmajiKabetaDevesh\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as SharmajiKabetaDevesh\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"SharmajiKabetaDevesh/Endtoend_Data_science-project_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"SharmajiKabetaDevesh/Endtoend_Data_science-project_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository SharmajiKabetaDevesh/Endtoend_Data_science-project_1 initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository SharmajiKabetaDevesh/Endtoend_Data_science-project_1 initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Mlops\\\\etoe1ds'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.chdir(\"etoe1ds\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key_id = os.getenv(\"access_key_id\")\n",
    "secret_access_key = os.getenv(\"secret_access_key\")\n",
    "MLFLOW_TRACKING_URI= os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "USER_NAME = os.getenv(\"USER_NAME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "@dataclass\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    test_data_path: Path\n",
    "    model_path: Path\n",
    "    all_params: dict\n",
    "    metric_file_name: Path\n",
    "    target_column: str\n",
    "    mflow_uri: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datascience.utils.common import save_json,read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datascience.constants import *\n",
    "class ModelEvaluationConfigManager:\n",
    "    def __init__(self,\n",
    "         config_path=CONFIG_FILE_PATH,\n",
    "         params_path=PARAMS_FILE_PATH,\n",
    "         schema_path=SCHEMA_FILE_PATH\n",
    "                 ):\n",
    "        self.config=read_yaml(config_path)\n",
    "        self.params=read_yaml(params_path)\n",
    "        self.schema=read_yaml(schema_path)\n",
    "\n",
    "    def get_evaluation_config_data(self):\n",
    "        config=self.config.model_evalaution\n",
    "        params=self.params.ElasticNet\n",
    "        schema = self.schema.target_value\n",
    "        create_directories([config.root_dir])\n",
    "        output=ModelEvaluationConfig(\n",
    "        root_dir=config.root_dir,\n",
    "    test_data_path = config.test_data_path,\n",
    "    model_path=config.model_path,\n",
    "    all_params ={\"alpha\":params.alpha,\n",
    "                 \"l1_ratio\":params.l1_ratio},\n",
    "    metric_file_name=config.metric_file_name,\n",
    "    target_column= schema.name,\n",
    "    mflow_uri=os.getenv(\"MLFLOW_TRACKING_URI\"),\n",
    "            )\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "class EvaluateModel:\n",
    "    def __init__(self,config=ModelEvaluationConfig):\n",
    "        self.config=config\n",
    "    \n",
    "    def eval_metrics(self,actual,pred):\n",
    "        rmse= np.sqrt(mean_squared_error(actual,pred))\n",
    "        mae= mean_absolute_error(actual,pred)\n",
    "        r2= r2_score(actual,pred)\n",
    "        return rmse,mae,r2\n",
    "    \n",
    "    def log_data_to_mlflow(self):\n",
    "        test_data=pd.read_csv(self.config.test_data_path)\n",
    "        model=joblib.load(self.config.model_path)\n",
    "\n",
    "        test_x= test_data.drop([self.config.target_column],axis=1)\n",
    "        test_y = test_data[[self.config.target_column]]\n",
    "\n",
    "        mlflow.set_registry_uri(self.config.mflow_uri)\n",
    "        tracking_uri=urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        with mlflow.start_run():\n",
    "            predicted_value= model.predict(test_x)\n",
    "            (rmse,mae,r2)=self.eval_metrics(test_y,predicted_value)\n",
    "\n",
    "            scores= {\"rmse\":rmse,\"mae\":mae, \"r2\":r2}\n",
    "            save_json(path=Path(self.config.metric_file_name),data=scores)\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metric(\"rmse\",rmse)\n",
    "            mlflow.log_metric(\"mae\",mae)\n",
    "            mlflow.log_metric(\"r2\",r2)\n",
    "            if tracking_uri!=\"file\":\n",
    "                mlflow.sklearn.log_model(model,\"model\",registered_model_name=\"ElasticNet\")\n",
    "            else:\n",
    "                mlflow.sklearn.log_model(model,\"model\")    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-29 17:12:51,906: INFO: common: yaml file: config\\config.yaml loading successfull]\n",
      "[2025-01-29 17:12:51,908: INFO: common: yaml file: params.yaml loading successfull]\n",
      "[2025-01-29 17:12:51,912: INFO: common: yaml file: schema.yaml loading successfull]\n",
      "[2025-01-29 17:12:51,914: INFO: common: Cretaed directory at:artifacts/model_evaluation]\n",
      "[2025-01-29 17:12:52,363: INFO: common: json file saved at artifacts\\model_evaluation\\metric.json]\n",
      "2025/01/29 17:13:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'ElasticNet'.\n",
      "2025/01/29 17:13:15 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ElasticNet, version 1\n",
      "Created version '1' of model 'ElasticNet'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run respected-moth-77 at: https://dagshub.com/SharmajiKabetaDevesh/Endtoend_Data_science-project_1.mlflow/#/experiments/0/runs/447b5218853448169a43e0f9037f0035\n",
      "🧪 View experiment at: https://dagshub.com/SharmajiKabetaDevesh/Endtoend_Data_science-project_1.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    obj= ModelEvaluationConfigManager()\n",
    "    config=obj.get_evaluation_config_data()\n",
    "    EvaluateModel(config).log_data_to_mlflow()\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "class PredictionPipeline:\n",
    "    def __init__(self):\n",
    "        self.model =joblib.load(Path('artifacts\\model_trainer\\model.joblib'))\n",
    "    \n",
    "    def predict(self,data):\n",
    "        prediction=self.model.predict(data)\n",
    "        return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Mlops\\ETOE1DS\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but ElasticNet was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "obj=PredictionPipeline()\n",
    "data = [7.4,0.7,0.0,1.9,0.076,11.0,34.0,0.9978,3.51,0.56,9.4]\n",
    "data=np.array(data).reshape(1,11)\n",
    "predict=obj.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.21050808]\n"
     ]
    }
   ],
   "source": [
    "print(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
